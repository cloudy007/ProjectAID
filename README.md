# Artificial Intelligence Drone 



<h2>Chapter1</h2>
<h3>1.1.Introduction</h3>
<p>This project aims to simplify drone control by developing a system that recognizes human gestures to execute basic maneuvers such as moving up, down, left, and right. By leveraging gesture recognition technology, the project explores whether hands-free operation can enhance the usability and accessibility of drones. This project seeks to address these gaps by developing a robust gesture recognition algorithm that utilizes deep learning and image processing techniques. This project not only aims to push the boundaries of drone technology but also aspires to pave the way for more intuitive control systems in future human-machine interactions.</p>
<h3>1.2.Problem Domain</h3>
<p>Traditional drone controls are typically complex and require manual input, which can make them difficult to use and access. This project aims to address these limitations by focusing on developing a gesture-based control system. which is crucial for a wide range of applications, from medical to military and civilian use.</p>
<h3>1.3.Problem Statement</h3>
<p>The project aims to develop a gesture-based control system to bridge the gap between user input and drone response. This will simplify the control process and make drones more accessible to users with varying levels of technical expertise. The benefits of this solution include improved user interaction, enhanced operational efficiency, and expanded potential applications of drone technology. This project is necessary to push the boundaries of current drone capabilities and to provide a more intuitive and practical control method, ultimately contributing to the evolution of human-computer interaction.</p>
<h3>1.4.Proposed System </h3>
<p>
1.4.1 Aims and Objectives
Aims: The primary aim of this project is to develop an advanced drone control system that utilizes gesture recognition to facilitate intuitive and hands-free operation. The goal is to create a system that can accurately understand and interpret hand gestures, translating them into various drone maneuvers and actions, including maneuvering, hovering, tracking, returning to the main state, and landing. This system will leverage or develop algorithms that enhance the drone's interaction capabilities, making its operation more accessible and user-friendly.
Objectives:
1.	Develop Gesture Recognition Algorithm
2.	Analyze Environmental Interactions
3.	Evaluate Code Implementation and Prioritization
4.	Simulate and Test Code Integration
5.	Improve and Optimize System
1.4.2 Proposed System Features
Feature List:
Tracking Objects/Colors
Hovering
Maneuvering
Defaulting State
</p>
<h3>1.5. Project Methodology </h3>
<p>The project will employ an Agile methodology to develop a gesture-based drone control system, which will allow for iterative development and continuous testing. This approach is suitable for a project that requires frequent adjustments and refinements, especially as we progress through stages of algorithm development, testing, and integration with the drone hardware. The methodology will involve a combination of research, algorithm development, system design, simulation, and testing phases to ensure a structured and replicable process.</p>
<h3>1.6.Resource Requirement </h3>
<p>This project requires a variety of resources to ensure the smooth execution of development, testing, and deployment phases. Proper planning and allocation of these resources are critical to achieving the project’s objectives and ensuring its successful completion.</p>
<h3>1.7. Project Management Plan </h3>
<p>The project is divided into several key phases: planning, development, testing, and deployment. The planning phase began in early September and involved setting up the project’s structure, identifying key objectives, and gathering necessary resources. This was followed by the development phase, where the main coding work for the gesture recognition system and drone controls took place, alongside algorithm implementation for tracking, hovering, and maneuvering.
Testing will occur during and after the development phase to ensure that each function operates correctly. The testing will involve simulations before transferring the system onto a physical drone, using both off-board computations and eventual direct drone implementation. This phase also includes debugging and optimizing the code for smooth performance.
Finally, the deployment phase will focus on finalizing the system, ensuring it meets all functional and performance requirements. During this phase, the project will be documented, tested in real-world scenarios, and prepared for final delivery and presentation.
Task Assignment and Roles
  
•	Rafat Alam: Responsible for coding, testing, designing and implementing algorithms, simulating the system, and contributing to documentation.

•	Abdulmohsen Alzahrani: Also tasked with coding, leads the testing process, implementing, simulating the project, and writing documentation.

•	Mohammed Bafageh: Oversees the documentation, analysis algorithms acts as the primary debugger, optimizes code, and testing.
</p>



